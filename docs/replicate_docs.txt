
Search 'best image models' or 'text to image'
cmd+k
Explore
Pricing
Enterprise
Docs
Blog
Sign in
Try for free
black-forest-labs/flux-kontext-pro

black-forest-labs
/
flux-kontext-pro 

Copy

A state-of-the-art text-based image editing model that delivers high-quality outputs with excellent prompt following and consistent results for transforming images through natural language

Warm
Official
34.1M runs
$0.04 per output image
Commercial use
Weights
Playground
API
Examples
README
FLUX.1 Kontext - Text-Based Image Editing
FLUX.1 Kontext is a state-of-the-art image editing model from Black Forest Labs that allows you to edit images using text prompts. It‚Äôs the best in class for text-guided image editing and offers superior results compared to other models like OpenAI‚Äôs 4o/gpt-image-1.

Available Models
FLUX.1 Kontext [dev]: Open-weight version with non-commercial license (commercial use available through Replicate)
FLUX.1 Kontext [pro]: State-of-the-art performance with high-quality outputs, great prompt following, and consistent results
FLUX.1 Kontext [max]: Premium model with maximum performance and improved typography generation
What You Can Do
Kontext excels at:

Style Transfer: Convert photos to different art styles (watercolor, oil painting, sketches)
Object/Clothing Changes: Modify hairstyles, add accessories, change colors
Text Editing: Replace text in signs, posters, and labels
Background Swapping: Change environments while preserving subjects
Character Consistency: Maintain identity across multiple edits
Prompting Best Practices
Be Specific
Use clear, detailed language with exact colors and descriptions
Avoid vague terms like ‚Äúmake it better‚Äù
Name subjects directly: ‚Äúthe woman with short black hair‚Äù vs. ‚Äúshe‚Äù
Preserve Intentionally
Specify what should stay the same: ‚Äúwhile keeping the same facial features‚Äù
Use ‚Äúmaintain the original composition‚Äù to preserve layout
For background changes: ‚ÄúChange the background to a beach while keeping the person in the exact same position‚Äù
Text Editing Tips
Use quotation marks: ‚Äúreplace ‚Äòold text‚Äô with ‚Äònew text‚Äô‚Äù
Stick to readable fonts
Match text length when possible to preserve layout
Style Transfer
Be specific about artistic styles: ‚Äúimpressionist painting‚Äù not ‚Äúartistic‚Äù
Reference known movements: ‚ÄúRenaissance‚Äù or ‚Äú1960s pop art‚Äù
Describe key traits: ‚Äúvisible brushstrokes, thick paint texture‚Äù
Complex Edits
Break into smaller steps for better results
Start simple and iterate
Use descriptive action verbs instead of ‚Äútransform‚Äù for more control
Commercial Use
When using FLUX.1 Kontext on Replicate, you‚Äôre free to use outputs commercially in apps, marketing, or any business use.

Example Applications
Check out these specialized apps built with Kontext:

Portrait series: Generate portrait variations from a single image
Change haircut: Modify hairstyles and colors
Iconic locations: Place subjects in famous landmarks
Professional headshot: Create professional portraits
Tips Summary
Be specific with colors, styles, and descriptions
Start simple and iterate on successful edits
Preserve intentionally by stating what to keep unchanged
Use quotation marks for exact text replacements
Control composition by specifying camera angles and framing
Choose verbs carefully - ‚Äúchange‚Äù vs ‚Äútransform‚Äù gives different results
Some services may be impacted
HomeAboutChangelogJoin usTermsPrivacyStatusSupport




Search 'best image models' or 'text to image'
cmd+k
Explore
Pricing
Enterprise
Docs
Blog
Sign in
Try for free
black-forest-labs/flux-kontext-pro

black-forest-labs
/
flux-kontext-pro 

Copy

A state-of-the-art text-based image editing model that delivers high-quality outputs with excellent prompt following and consistent results for transforming images through natural language

Warm
Official
34.1M runs
$0.04 per output image
Commercial use
Weights
Playground
API
Examples
README
Table of Contents


Node.js
Get started
Learn more
Schema
API reference
Use one of our client libraries to get started quickly.


Node.js

Python

HTTP
Set the REPLICATE_API_TOKEN environment variable

export REPLICATE_API_TOKEN=<paste-your-token-here>

Visibility

Copy
Learn more about authentication

Install Replicate‚Äôs Node.js client library

npm install replicate

Copy
Learn more about setup
Run black-forest-labs/flux-kontext-pro using Replicate‚Äôs API. Check out the model's schema for an overview of inputs and outputs.

import { writeFile } from "fs/promises";
import Replicate from "replicate";
const replicate = new Replicate();

const input = {
    prompt: "Make this a 90s cartoon",
    input_image: "https://replicate.delivery/pbxt/N55l5TWGh8mSlNzW8usReoaNhGbFwvLeZR3TX1NL4pd2Wtfv/replicate-prediction-f2d25rg6gnrma0cq257vdw2n4c.png",
    output_format: "jpg"
};

const output = await replicate.run("black-forest-labs/flux-kontext-pro", { input });

// To access the file URL:
console.log(output.url());
//=> "https://replicate.delivery/.../output.jpg"

// To write the file to disk:
await writeFile("output.jpg", output);
//=> output.jpg written to disk

Copy
Learn more
Some services may be impacted
HomeAboutChangelogJoin usTermsPrivacyStatusSupport



Apollo


Search 'best image models' or 'text to image'
cmd+k
Explore
Pricing
Enterprise
Docs
Blog
Sign in
Try for free
black-forest-labs/flux-kontext-pro

black-forest-labs
/
flux-kontext-pro 

Copy

A state-of-the-art text-based image editing model that delivers high-quality outputs with excellent prompt following and consistent results for transforming images through natural language

Warm
Official
34.1M runs
$0.04 per output image
Commercial use
Weights
Playground
API
Examples
README
Table of Contents


HTTP
Get started
Learn more
Schema
API reference
Use one of our client libraries to get started quickly.


Node.js

Python

HTTP
Set the REPLICATE_API_TOKEN environment variable

export REPLICATE_API_TOKEN=<paste-your-token-here>

Visibility

Copy
Learn more about authentication

Run black-forest-labs/flux-kontext-pro using Replicate‚Äôs API. Check out the model's schema for an overview of inputs and outputs.

curl --silent --show-error https://api.replicate.com/v1/models/black-forest-labs/flux-kontext-pro/predictions \
	--request POST \
	--header "Authorization: Bearer $REPLICATE_API_TOKEN" \
	--header "Content-Type: application/json" \
	--header "Prefer: wait" \
	--data @- <<'EOM'
{
	"input": {
      "prompt": "Make this a 90s cartoon",
      "input_image": "https://replicate.delivery/pbxt/N55l5TWGh8mSlNzW8usReoaNhGbFwvLeZR3TX1NL4pd2Wtfv/replicate-prediction-f2d25rg6gnrma0cq257vdw2n4c.png",
      "output_format": "jpg"
	}
}
EOM

Copy
Learn more
Some services may be impacted
HomeAboutChangelogJoin usTermsPrivacyStatusSupport



Apollo


Search 'best image models' or 'text to image'
cmd+k
Explore
Pricing
Enterprise
Docs
Blog
Sign in
Try for free

Search documentation
‚åò+/

Get started

Collapse sidebar
Run a model from Node.js
Run a model from Google Colab
Run a model from Python
Fine-tune an image model
Deploy a custom model

Guides

Run models
Build a website with Next.js
Build a Discord bot with Python
Build an app with SwiftUI
Make art with Stable Diffusion
Upscale images with AI models

Build models
Publish using GitHub Actions
Set up a CI/CD pipeline
Push your own model
Push a Transformers model
Push a Diffusers model
Optimize models with Pruna
Get a GPU on Brev
Get a GPU on Lambda Labs
Best practices for Replicate models
Optimize with torch.compile

Go deeper
Cache images with Cloudflare
Get started with ComfyUI
Use realtime speech with OpenAI
Handle webhooks with Val Town
Working with LoRAs

Topics

Models
About models
Run a model
Create a model
Publish a model
Model versions
Model hardware
Official models
Community models
Private and public models
Training destinations
Delete a model
Secrets

Predictions
About predictions
Create a prediction
Input files
Output files
Prediction lifecycle
Share a prediction
Rate limits
Safety checking
Data retention
Secrets
Streaming output

Deployments
About deployments
Create a deployment
View deployments
Monitor a deployment
Delete a deployment

Webhooks
About webhooks
Set up webhooks
Receive webhooks
Verify webhooks
Test your webhook code

Organizations
About organizations

Security
API tokens

Billing
About billing
Prepaid credit

Site policy
About subprocessors

Reference
How does Replicate work?
Client libraries
HTTP API
OpenAPI schema
Error codes
MCP server
Open source
Home / Guides / Run
Build a website with Next.js
Build a Next.js web app that uses Replicate to run models and receive webhooks as they run.

Copy page

Table of contents

Prerequisites
Step 1: Create the app
Step 2: Run the app locally
Step 3: Configure your environment
Step 4: Build the backend
Step 5: Build the frontend
Step 6: Add basic styles
Step 7: Configure image hosts
Step 8: Create a prediction
Step 9: Publish to GitHub
Step 10: Deploy to Vercel
Next steps
Learn how to build a Next.js web application that uses Replicate to run a machine learning model. By the end of this guide, you‚Äôll have your own deployed website that can accept text prompts as input and generate images using Flux Schnell, a fast and high-quality open-source image generation model from the creators of Stable Diffusion.

Tip
Want to skip ahead to the completed project? Check out the GitHub repo at replicate/getting-started-nextjs. There‚Äôs also a TypeScript version.
Prerequisites
Node.js: You‚Äôll need Node.js installed to be able to run your application locally. The easiest way to install Node.js is by downloading and running the package installer at nodejs.org.
An account on Replicate: You‚Äôll use Replicate to run machine learning models. It‚Äôs free to get started, and you get a bit of credit when you sign up. After that, you pay per second for your usage. See how billing works for more details.
An account on GitHub: This is where you‚Äôll host the source code for your application.
An account on Vercel: Vercel is a platform for hosting Next.js apps. This is where you‚Äôll deploy your web application.
Step 1: Create the app
Next.js is a framework for building web applications with JavaScript. You can use it to build apps that have both a Node.js backend web server and a React frontend. It‚Äôs a great choice for building web applications that use Replicate because it‚Äôs easy to get started with and it‚Äôs easy to deploy to Vercel.

The easiest way to get started with a new Next.js app is to use the create-next-app command:


Copy
npx create-next-app@latest --js --eslint
This command asks you to choose a name for your project and some options (you can accept all the defaults), then creates a project directory for you and installs the necessary dependencies. It also takes care of initializing a new Git repository and creating an initial commit with all the added files. This gives you a good starting point for managing your project‚Äôs source code history.

Step 2: Run the app locally
Now run your app locally to make sure everything is working:


Copy
cd my-app
npm run dev
You should have a running starter app at this point. View it in your browser at localhost:3000.

Step 3: Configure your environment
You need your API token to be able to run models. You can set it as an environment variable in your local development environment.

Generate an API token at replicate.com/account/api-tokens and copy the token.

Next.js has built-in support for loading environment variables from a .env.local file into process.env.

Create a file called .env.local in the root of your project:


Copy
touch .env.local
Then edit the file and add your token to it:


Copy
REPLICATE_API_TOKEN=r8_...
Note: The npx create-next-app command you ran in Step 1 created a .gitignore file that ignores .env.local files. This is a good thing, because you don‚Äôt want to accidentally commit your API token to your project‚Äôs source code repository.

Step 4: Build the backend
Now it‚Äôs time to write some server-side code that you‚Äôll use to run models with Replicate.

One of the great things about Next.js is that you can write your backend code in the same project as your frontend code. Any code in a page.js file is treated as a frontend component, and any code in a route.js file is treated as a backend API endpoint.

You‚Äôll create two server-side endpoints: one for running the model and one for polling the status of that request until it‚Äôs complete.

Start by creating a directory for these endpoints:


Copy
mkdir -p app/api/predictions
Now create a file to handle prediction creation requests. Call it app/api/predictions/route.js and add the following code:


Copy
import { NextResponse } from "next/server";
import Replicate from "replicate";

const replicate = new Replicate({
  auth: process.env.REPLICATE_API_TOKEN,
});

// In production and preview deployments (on Vercel), the VERCEL_URL environment variable is set.
// In development (on your local machine), the NGROK_HOST environment variable is set.
const WEBHOOK_HOST = process.env.VERCEL_URL
  ? `https://${process.env.VERCEL_URL}`
  : process.env.NGROK_HOST;

export async function POST(request) {
  if (!process.env.REPLICATE_API_TOKEN) {
    throw new Error(
      'The REPLICATE_API_TOKEN environment variable is not set. See README.md for instructions on how to set it.'
    );
  }

  const { prompt } = await request.json();

  const options = {
    model: 'black-forest-labs/flux-schnell',
    input: { prompt }
  }

  if (WEBHOOK_HOST) {
    options.webhook = `${WEBHOOK_HOST}/api/webhooks`
    options.webhook_events_filter = ["start", "completed"]
  }

  // A prediction is the result you get when you run a model, including the input, output, and other details
  const prediction = await replicate.predictions.create(options);

  if (prediction?.error) {
    return NextResponse.json({ detail: prediction.error }, { status: 500 });
  }

  return NextResponse.json(prediction, { status: 201 });
}
Now create a file to handle requests to poll for the prediction‚Äôs status. Call it app/api/predictions/[id]/route.js and add the following code:


Copy
import { NextResponse } from "next/server";
import Replicate from "replicate";

const replicate = new Replicate({
  auth: process.env.REPLICATE_API_TOKEN,
});

export async function GET(request, context) {
  const { id } = await context.params;
  const prediction = await replicate.predictions.get(id);

  if (prediction?.error) {
    return NextResponse.json({ detail: prediction.error }, { status: 500 });
  }

  return NextResponse.json(prediction);
}
Note the [id] in the directory structure. Next.js has a feature called dynamic routing that treats the id part of the URL as a variable. You can use this variable in your code by accessing req.query.id.

Step 5: Build the frontend
You‚Äôve finished writing the server-side code that talks to Replicate. Now it‚Äôs time to create the frontend code that renders a form. When a user enters a prompt and submits the form, it posts the data to the server-side endpoint that you created in Step 4. The endpoint runs the model with Replicate and returns a prediction (an object representing a single model run).

Your project already has a file called app/page.js that renders the default ‚ÄúWelcome to Next.js‚Äù home route. Remove all the existing content in that file and replace it with the following code:


Copy
'use client';

import { useState } from "react";
import Image from "next/image";

const sleep = (ms) => new Promise((r) => setTimeout(r, ms));

export default function Home() {
  const [prediction, setPrediction] = useState(null);
  const [error, setError] = useState(null);

  const handleSubmit = async (e) => {
    e.preventDefault();
    const response = await fetch("/api/predictions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        prompt: e.target.prompt.value,
      }),
    });
    let prediction = await response.json();
    if (response.status !== 201) {
      setError(prediction.detail);
      return;
    }
    setPrediction(prediction);

    while (
      prediction.status !== "succeeded" &&
      prediction.status !== "failed"
    ) {
      await sleep(1000);
      const response = await fetch("/api/predictions/" + prediction.id);
      prediction = await response.json();
      if (response.status !== 200) {
        setError(prediction.detail);
        return;
      }
      console.log({ prediction: prediction });
      setPrediction(prediction);
    }
  };

  return (
    <div className="container max-w-2xl mx-auto p-5">
      <h1 className="py-6 text-center font-bold text-2xl">
        Dream something with{" "}
        <a href="https://replicate.com/black-forest-labs/flux-schnell?utm_source=project&utm_project=getting-started">
          Flux Schnell
        </a>
      </h1>

      <form className="w-full flex" onSubmit={handleSubmit}>
        <input
          type="text"
          className="flex-grow"
          name="prompt"
          placeholder="Enter a prompt to display an image"
        />
        <button className="button" type="submit">
          Go!
        </button>
      </form>

      {error && <div>{error}</div>}

      {prediction && (
        <>
          {prediction.output && (
            <div className="image-wrapper mt-5">
              <Image
                src={prediction.output[prediction.output.length - 1]}
                alt="output"
                sizes="100vw"
                height={768}
                width={768}
              />
            </div>
          )}
          <p className="py-3 text-sm opacity-50">status: {prediction.status}</p>
        </>
      )}
    </div>
  );
}
Step 6: Add basic styles
The Next.js starter app includes some CSS styles that are used on the default splash page, but they aren‚Äôt really intended to be reused for a real app.

To create a clean slate for your styles, remove all the content in app/globals.css and replace it with the following basic styles:


Copy
@tailwind base;
@tailwind components;
@tailwind utilities;

.container {
  padding: 2rem;
  font-size: 1.3rem;
  max-width: 48rem;
  margin: 0 auto;
}

form {
  display: flex;
  margin-bottom: 2rem;
}

form input {
  width: 100%;
  padding: 1rem;
  border: 1px solid #000;
  border-radius: 0.25rem;
  font-size: 1.3rem;
  margin-right: 1rem;
}

form button {
  padding: 1rem;
  border: none;
  border-radius: 0.25rem;
  box-sizing: border-box;
  cursor: pointer;
  font-size: 1.3rem;
}

.imageWrapper {
  width: 100%;
  aspect-ratio: 1 / 1;
  position: relative;
}
Step 7: Configure image hosts
To protect your application from malicious users, Next.js requires some configuration to use external images. Edit the next.config.js file and add replicate.com and replicate.delivery to the images.domains array:


Copy
const nextConfig = {
  reactStrictMode: true,
  images: {
    remotePatterns: [
      {
        protocol: "https",
        hostname: "replicate.com",
      },
      {
        protocol: "https",
        hostname: "replicate.delivery",
      },
    ],
  },
};

export default nextConfig;
Step 8: Create a prediction
Your app should be ready to use now! Visit localhost:3000 and enter a prompt to see the results.

studio portrait photo of an iguana wearing a hat
Step 9: Publish to GitHub
Now that your app is working, it‚Äôs time to publish it to a GitHub repository. This step is not strictly necessary, but it‚Äôs a good idea to keep your code in a version control system like Git. This will also set you up nicely to use Vercel‚Äôs GitHub integration, which deploys your app automatically every time you push a new commit to the main branch on GitHub.

First, commit your changes to Git:


Copy
git add pages/api/predictions/
git commit -am "First working version! üéâ"
Then create a new GitHub repository and push your code to it. You can use whatever flow you like, but here we‚Äôll go with the following command that uses GitHub‚Äôs official gh CLI to create a new public repo named my-replicate-app and push your code to it:


Copy
gh repo create my-replicate-app --public --push --source=.
If you‚Äôd rather keep your repository private, set the --private flag instead of --public.

Step 10: Deploy to Vercel
There are many ways to deploy apps to Vercel, but for the sake of brevity, we‚Äôll use the vercel CLI here. Start by installing the CLI and running it:


Copy
npx vercel
The command above installs the CLI, then walks you through the process of logging in to Vercel, creating the app, and deploying it.

Once you‚Äôve deployed your app, you need to add your API token to the remote app‚Äôs environment variables. This allows your app to make requests to Replicate.


Copy
npx vercel env add REPLICATE_API_TOKEN
The command above prompts you to enter a value for your token. Paste the same token you used in Step 3. You then need to deploy again:


Copy
npx vercel deploy --prod
Next steps
You did it! You should now have a working web app that‚Äôs powered by machine learning.

But this is just the start. Here are some ideas for what you can do next:

üòé Show your friends what you‚Äôve built.

ü™ù Update your app to request and receive webhooks so you can do things like store your prediction metadata in a database. See the webhooks docs in the getting-started-nextjs repo.

üöÇ Fine-tune and deploy your own custom Flux Schnell image generation model and use your new website to show it off.

üîé Integrate a super resolution model into your new app to upscale the generated images to a higher resolution.

ü§ñ Explore other models on Replicate and integrate them into your app.

‚úçÔ∏è Update the README if you‚Äôre planning to open-source your project so others know how to use it and contribute.

‚ö°Ô∏è Connect your Vercel app to your GitHub repo, so you‚Äôll get preview deployments for every pull request, and your app will automatically deploy every time you push to the main branch.

Next:
Build a Discord bot with Python
Some services may be impacted
HomeAboutChangelogJoin usTermsPrivacyStatusSupport



Build a website with Next.js - Replicate


